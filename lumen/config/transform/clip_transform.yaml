train:
  _target_: torchvision.transforms.Compose
  transforms: 
    - _target_: torchvision.transforms.RandomResizedCrop
      size: 224
      scale: 
        - 0.08
        - 1.0
      interpolation: 3
    
    - _target_: lumen.dataset_uq.utils.ConvertImageToRGB
    - _target_: torchvision.transforms.RandomHorizontalFlip
    - _target_: torchvision.transforms.ToTensor
    - _target_: torchvision.transforms.Normalize
      mean: 
        - 0.48145466
        - 0.4578275
        - 0.40821073
      std: 
        - 0.26862954
        - 0.26130258
        - 0.27577711

val:
  _target_: torchvision.transforms.Compose
  transforms:
    - _target_: torchvision.transforms.Resize
      size: 224
      interpolation: 3
    - _target_: torchvision.transforms.CenterCrop
      size: 224
    - _target_: lumen.dataset_uq.utils.ConvertImageToRGB
    - _target_: torchvision.transforms.ToTensor
    - _target_: torchvision.transforms.Normalize
      mean: 
        - 0.48145466
        - 0.4578275
        - 0.40821073
      std: 
        - 0.26862954
        - 0.26130258
        - 0.27577711

