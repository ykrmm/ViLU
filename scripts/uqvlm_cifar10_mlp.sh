PYTHONWARNINGS="ignore" CUDA_VISIBLE_DEVICES="1" python lumen/run.py \
 exp_name="uqvlm_mlp_2" \
 dataset=cifar10 \
 backbone=clip_vit_b32 \
 zs_datasets=data_suite \
 model=confidnetvlm_attention \
 model.keep_frozen=true \
 model.n_iter_freeze_proj=1000 \
 model.use_predicted_caption=true \
 model.use_attention=true \
 model.layers=[512,1] \
 engine.n_epochs=500 \
 engine.batchwise_train=false \
 engine.eval_zs=false \
 engine.eval_only=false \
 resume=False \
 loss.weight=10 \
 optimizer.lr=0.01 \
 batch_size=128 \
 cluster_env=cnam \
 wandb_mode=online \
 debug=false \


PYTHONWARNINGS="ignore" CUDA_VISIBLE_DEVICES="1" python lumen/run.py \
 exp_name="uqvlm_mlp_3" \
 dataset=cifar10 \
 backbone=clip_vit_b32 \
 zs_datasets=data_suite \
 model=confidnetvlm_attention \
 model.keep_frozen=true \
 model.n_iter_freeze_proj=1000 \
 model.use_predicted_caption=true \
 model.use_attention=true \
 model.layers=[512,128,1] \
 engine.n_epochs=500 \
 engine.batchwise_train=false \
 engine.eval_zs=false \
 engine.eval_only=false \
 resume=False \
 loss.weight=10 \
 optimizer.lr=0.01 \
 batch_size=128 \
 cluster_env=cnam \
 wandb_mode=online \
 debug=false \

PYTHONWARNINGS="ignore" CUDA_VISIBLE_DEVICES="1" python lumen/run.py \
 exp_name="uqvlm_mlp_5" \
 dataset=cifar10 \
 backbone=clip_vit_b32 \
 zs_datasets=data_suite \
 model=confidnetvlm_attention \
 model.keep_frozen=true \
 model.n_iter_freeze_proj=1000 \
 model.use_predicted_caption=true \
 model.use_attention=true \
 model.layers=[512,512,256,128,1] \
 engine.n_epochs=500 \
 engine.batchwise_train=false \
 engine.eval_zs=false \
 engine.eval_only=false \
 resume=False \
 loss.weight=10 \
 optimizer.lr=0.01 \
 batch_size=128 \
 cluster_env=cnam \
 wandb_mode=online \
 debug=false \

PYTHONWARNINGS="ignore" CUDA_VISIBLE_DEVICES="1" python lumen/run.py \
 exp_name="uqvlm_mlp_6" \
 dataset=cifar10 \
 backbone=clip_vit_b32 \
 zs_datasets=data_suite \
 model=confidnetvlm_attention \
 model.keep_frozen=true \
 model.n_iter_freeze_proj=1000 \
 model.use_predicted_caption=true \
 model.use_attention=true \
 model.layers=[512,512,512,256,128,1] \
 engine.n_epochs=500 \
 engine.batchwise_train=false \
 engine.eval_zs=false \
 engine.eval_only=false \
 resume=False \
 loss.weight=10 \
 optimizer.lr=0.01 \
 batch_size=128 \
 cluster_env=cnam \
 wandb_mode=online \
 debug=false \