{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval and visualisation (Caltech101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from lumen.models.clip import load as load_clip\n",
    "from lumen.models.clip import tokenize as clip_tokenize\n",
    "from lumen.models import LuMenAttention\n",
    "from lumen.dataset_uq.utils import ConvertImageToRGB  \n",
    "from lumen.dataset_uq import Caltech101Dataset\n",
    "import lumen.lib as lib\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading backbone dataset and uncertainties model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvu_path = '../weights/lvu_caltech.ckpt'\n",
    "lumen_path = '../weights/lumen_caltech.ckpt'\n",
    "visu_path = '../visu/caltech'\n",
    "os.makedirs(visu_path,exist_ok=True)\n",
    "dataset = 'Caltech101'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "clip_model, _ = load_clip(\"ViT-B/32\")\n",
    "clip_model.to(device)\n",
    "print('CLIP model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(224, interpolation=transforms.InterpolationMode.BICUBIC), \n",
    "    transforms.CenterCrop(224),\n",
    "    ConvertImageToRGB(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "        std=[0.26862954, 0.26130258, 0.27577711]\n",
    "    )\n",
    "])\n",
    "dts_val = Caltech101Dataset('../data/caltech101',split='test',transform=val_transforms)\n",
    "dataloader_val = DataLoader(dts_val, batch_size=128, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lvu = LuMenAttention(\n",
    "                                        concat=True,\n",
    "                                        identity_init=True,\n",
    "                                        n_iter_freeze_proj=1000,\n",
    "                                        use_predicted_caption=False,\n",
    "                                        use_attention=False,\n",
    "                                        )\n",
    "\n",
    "lumen = LuMenAttention(\n",
    "                                        concat=True,\n",
    "                                        identity_init=True,\n",
    "                                        n_iter_freeze_proj=1000,\n",
    "                                        use_predicted_caption=True,\n",
    "                                        use_attention=True,\n",
    "                                        )\n",
    "\n",
    "\n",
    "template = \"A photo of a {}.\"\n",
    "logit_scale = lumen.logit_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvu.load_state_dict(torch.load(lvu_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')['state_dict'])\n",
    "lumen.load_state_dict(torch.load(lumen_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')['state_dict'])\n",
    "lvu.to(device)\n",
    "lumen.to(device)\n",
    "lvu.eval()\n",
    "lumen.eval()\n",
    "print('Models loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate pretrain LuMen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvu_success = []\n",
    "lvu_failure = []\n",
    "lumen_success = []\n",
    "lumen_failure = []\n",
    "missclassifieds = []\n",
    "tcps_success = []\n",
    "tcps_failure = []\n",
    "mcps_success = []\n",
    "mcps_failure = []\n",
    "total_iter = 0\n",
    "with torch.no_grad():\n",
    "    class_names = dataloader_val.dataset.class_names\n",
    "    class_names = clip_tokenize([template.format(name) for name in class_names])\n",
    "    for i, batch in enumerate(dataloader_val):\n",
    "        images = batch[\"image\"]\n",
    "        labels = batch[\"target\"].to(device)\n",
    "        visual_feats = clip_model.encode_image(images.to(device))\n",
    "        visual_feats /= visual_feats.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        text_feats = clip_model.encode_text(class_names.to(device))\n",
    "        text_feats /= text_feats.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        probs = torch.softmax(logit_scale * visual_feats @ text_feats.t(), dim=-1)\n",
    "        with torch.autocast(device_type='cuda'):\n",
    "            lvu_scores = lvu(visual_feats, text_feats).squeeze(-1)\n",
    "            lumen_scores = lumen(visual_feats, text_feats).squeeze(-1)\n",
    "\n",
    "        missclassified = labels != probs.argmax(dim=-1)\n",
    "\n",
    "        tcps = probs[torch.arange(labels.size(0)), labels]\n",
    "        mcps = probs.max(dim=-1).values\n",
    "\n",
    "        lvu_success.append(lvu_scores[~missclassified])\n",
    "        lvu_failure.append(lvu_scores[missclassified])\n",
    "        lumen_success.append(lumen_scores[~missclassified])\n",
    "        lumen_failure.append(lumen_scores[missclassified])\n",
    "        missclassifieds.append(missclassified)\n",
    "        mcps_success.append(mcps[~missclassified])\n",
    "        mcps_failure.append(mcps[missclassified])\n",
    "    \n",
    "    missclassifieds = torch.cat(missclassifieds).cpu().numpy()\n",
    "    lvu_success_sigmoid = torch.sigmoid(torch.cat(lvu_success)).cpu().numpy()\n",
    "    lvu_failure_sigmoid = torch.sigmoid(torch.cat(lvu_failure)).cpu().numpy()\n",
    "    lumen_success_sigmoid = torch.sigmoid(torch.cat(lumen_success)).cpu().numpy()\n",
    "    lumen_failure_sigmoid = torch.sigmoid(torch.cat(lumen_failure)).cpu().numpy()\n",
    "    lvu_success = torch.cat(lvu_success).cpu().numpy()\n",
    "    lvu_failure = torch.cat(lvu_failure).cpu().numpy()\n",
    "    lumen_success = torch.cat(lumen_success).cpu().numpy()\n",
    "    lumen_failure = torch.cat(lumen_failure).cpu().numpy()\n",
    "    mcps_success = torch.cat(mcps_success).float().cpu().numpy()\n",
    "    mcps_failure = torch.cat(mcps_failure).float().cpu().numpy()\n",
    "\n",
    "    fpr_lvu = lib.get_fpr(lvu_success, lvu_failure)\n",
    "    auc_lvu = lib.get_auroc(lvu_success, lvu_failure)\n",
    "\n",
    "    fpr_lumen = lib.get_fpr(lumen_success, lumen_failure)\n",
    "    auc_lumen = lib.get_auroc(lumen_success, lumen_failure)\n",
    "\n",
    "    fpr_mcm = lib.get_fpr(mcps_success, mcps_failure)\n",
    "    auc_mcm = lib.get_auroc(mcps_success, mcps_failure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f\"AUC MCM: {auc_mcm:.4f}\")\n",
    "print(f\"FPR MCM: {fpr_mcm:.4f}\")\n",
    "print(f\"AUC LVU: {auc_lvu:.4f}\")\n",
    "print(f\"FPR LVU: {fpr_lvu:.4f}\")\n",
    "print(f\"AUC LuMen: {auc_lumen:.4f}\")\n",
    "print(f\"FPR LuMen: {fpr_lumen:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_gaussian_distributions(mcps_success, mcps_failure, \n",
    "                                lvu_success, lvu_failure, \n",
    "                                lumen_success, lumen_failure):\n",
    "\n",
    "\n",
    "    plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "    plt.rcParams[\"font.sans-serif\"] = [\"Nimbus Sans\"]\n",
    "    plt.rcParams['font.weight'] = 'bold'\n",
    "    plt.rcParams['axes.labelsize'] = 24  \n",
    "    plt.rcParams['xtick.labelsize'] = 26  \n",
    "    plt.rcParams['ytick.labelsize'] = 26  \n",
    "    sns.set_theme(style=\"ticks\")\n",
    "\n",
    "\n",
    "    success_color = \"#1E3A8A\"  \n",
    "    failure_color = \"#8B0000\"  \n",
    "\n",
    "    methods = [\n",
    "        (mcps_success, mcps_failure, \"MCM\"),\n",
    "        (lvu_success, lvu_failure, \"lvu\"),\n",
    "        (lumen_success, lumen_failure, \"LuMen\")\n",
    "    ]\n",
    "    \n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    for i, (success, failure, method) in enumerate(methods):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "\n",
    "\n",
    "        success_kde = gaussian_kde(success)\n",
    "        failure_kde = gaussian_kde(failure)\n",
    "\n",
    "        x_vals = np.linspace(0, 1, 300)\n",
    "\n",
    "        success_density = success_kde(x_vals)\n",
    "        failure_density = failure_kde(x_vals)\n",
    "\n",
    "        plt.fill_between(x_vals, success_density, color=success_color, alpha=0.4, \n",
    "                         edgecolor='black', linewidth=2, label=\"Success\")\n",
    "        plt.fill_between(x_vals, failure_density, color=failure_color, alpha=0.8, \n",
    "                         edgecolor='black', linewidth=2, label=\"Failure\")\n",
    "\n",
    "        plt.title(f\"{method}\", fontsize=26, fontweight='bold')\n",
    "\n",
    "        if i == 1:\n",
    "            plt.xlabel(\"Uncertainty Score\", fontsize=30, fontweight='bold')\n",
    "        if i == 0:  \n",
    "            plt.ylabel(\"Density \"+dataset, fontsize=30, fontweight='bold')\n",
    "\n",
    "        ax = plt.gca()\n",
    "        ax.spines['bottom'].set_linewidth(3)  \n",
    "        ax.spines['left'].set_linewidth(3)    \n",
    "        ax.tick_params(axis='x', which='major', width=3, length=10) \n",
    "        ax.tick_params(axis='y', which='major', width=3, length=10)  \n",
    "        \n",
    "        for tick in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "            tick.set_fontweight('bold')\n",
    "            tick.set_fontsize(24)\n",
    "\n",
    "        plt.grid(True, linestyle=\"--\", linewidth=1.5, alpha=0.6)\n",
    "\n",
    "    plt.legend(fontsize=24, loc='upper right', framealpha=1, handletextpad=0.2, \n",
    "               columnspacing=0.4, handlelength=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = f\"{visu_path}/failure_{dataset}.png\"\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_gaussian_distributions(1 - mcps_success, 1 - mcps_failure, 1 - lvu_success_sigmoid, 1 - lvu_failure_sigmoid, 1 - lumen_success_sigmoid, 1 - lumen_failure_sigmoid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lscaleuq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
